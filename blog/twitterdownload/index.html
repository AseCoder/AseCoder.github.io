<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<title>How to download videos from Twitter</title>
	<link rel="stylesheet" href="../../font.css">
	<link rel="stylesheet" href="../../v3-posts.css">
	<meta name="theme-color" content="#946c4b">
	<meta name="description" content="A tutorial">
</head>
<body>
	<article>
		<h1>How to download videos from Twitter</h1>
		<p>For the technologically inclined. Working as of 2024-11-20.</p>
		<h2>1. Finding the video URL</h2>
		<p>When you have navigated to the twitter video you would like to download, open the network tab in your browser's developer tools. Refresh the page. Then look for a request whose domain starts with <code>prod-</code>, file name starts with <code>master_dynamic</code> and file extension is <code>.m3u8</code>. This request only happens once and it happens when the page loads. Copy the whole URL of the request. Do not copy the <code>playlist_</code> URL as I've found that that one doesn't include HD streams.</p>
		<img src="devtools.png" alt="The request highlighted in the network tab">
		<p>There is another type of URL, too: its domain name is <code>video.twimg.com</code> and the file extension and file type (<code>x-mpegurl</code>) are the same. There is no <code>master_dynamic</code> file, but I succeeded by copying the URL of the first request.</p>
		<img src="devtools2.png" alt="The request highlighted in the network tab">
		<h2>2. Downloading with FFMPEG</h2>
		<p>Using the command prompt, navigate to the directory in which you would like to save the video. Then run the following command: <code>ffmpeg -i "the url you copied" -c copy output.mp4</code></p>
		<p>This points FFMPEG to download the video stream from the internet and save it to a file. The console will spew a lot of nonsense as it downloads each individual <code>chunk</code> of the video.</p>
		<h2>Tips & tricks</h2>
		<ul>
			<li>
				<p>If the download hangs, it might be beneficial to add <code>-rw_timeout [microseconds]</code> before <code>-i</code> to
				make FFMPEG retry if the network request times out. Try, for example, 5 seconds: <code>5000000</code>.</p>
			</li>
			<li>
				<p>According to my experimentation, though, this corrupts the parts of the output file where a network timeout or
				<code>timestamp discontinuity</code> happens. <b>For this I prescribe <code>-fflags +genpts</code> and
				<code>-reset_timestamps 1</code> immediately after the input file</b>, though I'm not sure which of these fixes the problem.</p>
			</li>
			<li>
				<p><b>You might also try downloading the video and audio separately using <code>-map</code> and then combining them.</b></p>
			</li>
			<li>
				<p>When downloading a livestream live, you could try adding <code>-re</code> to the beginning.</p>
			</li>
			<li>
				<p>If Twitter only gives you a <code>master_dynamic_highlatency.m3u8</code>, you can try swapping out "high" for "low" to access the low-latency stream. <b>This is beneficial especially when playing the livestream in VLC instead of the Twitter client.</b></p>
			</li>
			<li style="color: yellow;">
				<p><code>timestamp discontinuity</code> is a significant problem when downloading livestreams live. Further experimentation is required.</p>
			</li>
			<li style="color: yellow;">
				<p>When downloading the streams separately, it might not be necessary to run two commands. Just have two outputs instead.</p>
			</li>
		</ul>
		<p>
			In conclusion, I've found the following works best for downloading a replay of a livestream:
			<br>
			<code>ffmpeg -rw_timeout 3000000 -i
			"url"
			-fflags +genpts -reset_timestamps 1 -map 0:[id of video stream] -c copy output_v.mp4</code>
			<br>
			<code>ffmpeg -rw_timeout 3000000 -i
			"url"
			-fflags +genpts -reset_timestamps 1 -map 0:[id of audio stream] -c copy output_a.mp4</code>
			<br>
			And then combining the two:
			<br>
			<code>ffmpeg -i output_v.mp4 -i output_a.mp4 -c copy output.mp4</code>
		</p>
	</article>
</body>
</html>